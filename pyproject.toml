[build-system]
requires = ["flit_core >=3.2,<4"]
build-backend = "flit_core.buildapi"

[project]
name = "neural_fcasa"
version = "0.0.1"
description = "A package for Neural FCASA"
readme = "README.md"
requires-python = ">=3.10"
license = { file = "LICENSE" }
authors = [
    { name = "National Institute of Advanced Industrial Science and Technology", email = "y.bando@aist.go.jp" },
]
classifiers = ["License :: OSI Approved :: MIT License"]
dependencies = [
    "aiaccel@git+https://github.com/aistairc/aiaccel.git@649adc0f321d2e37b5ffe22de723ba2b9b5c8d6b",
    "einops>=0.8.0",
    "torch>=2.3.0",
    "lightning>=2.2.3",
    "numpy>=1.24.3",
    "matplotlib>=3.8.3",
    "soundfile",
    "hydra-core",
    "omegaconf",
    "torchaudio",
    "kornia",
    "huggingface_hub",
    "rich",
    "nara_wpe"
]

[project.optional-dependencies]
dev = [
    "ruff"
]

[project.urls]
Home = "https://ybando.jp"

[tool.ruff]
line-length = 120
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "UP", "B", "SIM", "I"]

[tool.ruff.lint.isort]
force-sort-within-sections = true

section-order = [
    "future",
    "typing",
    "standard-library",
    "utilities",
    "datascience",
    "torch",
    "torch-third-party",
    "third-party",
    "audio",
    "first-party",
    "local-folder",
]

[tool.ruff.lint.isort.sections]
"typing" = ["typing"]
"utilities" = ["progressbar", "omegaconf", "hydra"]
"datascience" = [
    "numpy",
    "scipy",
    "pandas",
    "matplotlib",
    "opt_einsum",
    "einops",
]
"torch" = ["torch"]
"torch-third-party" = [
    "torchaudio",
    "torchvision",
    "auraloss",
    "lightning",
    "einops.layers",
]
"audio" = ["librosa", "pypesq", "pystoi", "soundfile"]

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401"]
